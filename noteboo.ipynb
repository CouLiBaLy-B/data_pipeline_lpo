{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convertir_date(date_string):\n",
    "    try:\n",
    "        # Convertir en objet datetime\n",
    "        date_obj = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "        \n",
    "        # Extraire la date au format souhaité (aaaa-mm-jj)\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    except ValueError:\n",
    "        return \"Format de date invalide. Assurez-vous que la chaîne est au format 'aaaa-mm-jjThh:mm:ss.ssssss+hh:mm'.\"\n",
    "\n",
    "# Exemple d'utilisation\n",
    "date_string = '2021-03-26T10:55:53.379470+01:00'\n",
    "resultat = convertir_date(date_string)\n",
    "print(resultat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>create_datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>structure</th>\n",
       "      <th>elevation</th>\n",
       "      <th>provider</th>\n",
       "      <th>update_datetime</th>\n",
       "      <th>region</th>\n",
       "      <th>departement</th>\n",
       "      <th>Pays</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>janvier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>fevrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>avril</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>mai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index create_datetime   id  \\\n",
       "0      0      2021-03-26  997   \n",
       "1      0      2021-03-26  997   \n",
       "2      0      2021-03-26  997   \n",
       "3      0      2021-03-26  997   \n",
       "4      0      2021-03-26  997   \n",
       "\n",
       "                                         description  \\\n",
       "0  Un Parc national est un territoire reconnu com...   \n",
       "1  Un Parc national est un territoire reconnu com...   \n",
       "2  Un Parc national est un territoire reconnu com...   \n",
       "3  Un Parc national est un territoire reconnu com...   \n",
       "4  Un Parc national est un territoire reconnu com...   \n",
       "\n",
       "                                   name                    structure  \\\n",
       "0  Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "1  Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "2  Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "3  Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "4  Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "\n",
       "   elevation provider update_datetime                      region  \\\n",
       "0        NaN               2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "1        NaN               2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "2        NaN               2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "3        NaN               2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "4        NaN               2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "\n",
       "               departement    Pays   months  \n",
       "0  Alpes-de-Haute-Provence  France  janvier  \n",
       "1  Alpes-de-Haute-Provence  France  fevrier  \n",
       "2  Alpes-de-Haute-Provence  France     mars  \n",
       "3  Alpes-de-Haute-Provence  France    avril  \n",
       "4  Alpes-de-Haute-Provence  France      mai  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "# URL de l'API\n",
    "api_url = \"https://biodiv-sports.fr/api/v2/sensitivearea/\"\n",
    "\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"myApplication\")\n",
    "\n",
    "def get_location_info(latitude, longitude):\n",
    "    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "    address = location.raw['address']\n",
    "    region = address.get('state', '')\n",
    "    country = address.get('country', '')\n",
    "    departement = address.get('county', '')\n",
    "    return  region, departement, country\n",
    "\n",
    "\n",
    "def convertir_date(date_string):\n",
    "    try:\n",
    "        # Convertir en objet datetime\n",
    "        date_obj = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "        \n",
    "        # Extraire la date au format souhaité (aaaa-mm-jj)\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    except ValueError:\n",
    "        return \"Format de date invalide. Assurez-vous que la chaîne est au format 'aaaa-mm-jjThh:mm:ss.ssssss+hh:mm'.\"\n",
    "\n",
    "def add_months_names(df):\n",
    "    # Ajouter le nom du mois\n",
    "    months_list = ['janvier', 'fevrier', 'mars', 'avril', 'mai', 'juin', 'juillet', 'août', 'septembre', 'octobre', 'novembre', 'decembre']\n",
    "    df_with_months = df.assign(\n",
    "        months=df['period'].apply(lambda x: [months_list[i] for i, value in enumerate(x) if value == 1])\n",
    "    )\n",
    "    return df_with_months\n",
    "\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    # Obtenez le texte sans balises HTML\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    cleaned_text = soup.get_text()\n",
    "    \n",
    "    return cleaned_text \n",
    "\n",
    "\n",
    "def data_extract(api_url):\n",
    "    # Récupération des données depuis l'API\n",
    "    response = requests.get(api_url)\n",
    "    res = response.json()\n",
    "    res = res[\"results\"]\n",
    "    return res\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def data_transformation(res: list) -> pd.DataFrame:\n",
    "    # Préparation des données pour la création du DataFrame\n",
    "    data = [{\n",
    "        \"create_datetime\": convertir_date(item[\"create_datetime\"]),\n",
    "        \"id\": item[\"id\"],\n",
    "        \"description\": remove_html_tags(item[\"description\"][\"fr\"]),\n",
    "        \"name\": item[\"name\"][\"fr\"],\n",
    "        \"structure\": item[\"structure\"],\n",
    "        \"elevation\": item[\"elevation\"],\n",
    "        \"provider\": item[\"provider\"],\n",
    "        \"coordonnees\": item[\"geometry\"][\"coordinates\"][0][0][0] if item[\"geometry\"][\"type\"] == \"MultiPolygon\" else item[\"geometry\"][\"coordinates\"][0][0],\n",
    "        \"period\": [int(bool_) for bool_ in item[\"period\"]] if isinstance(item[\"period\"], list) else item[\"period\"],\n",
    "        \"update_datetime\": convertir_date(item[\"update_datetime\"])\n",
    "    } for item in res]\n",
    "\n",
    "    # Création du DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    df[[\"region\", \"departement\", \"Pays\"]] = list(df[\"coordonnees\"].apply(lambda raw: get_location_info(raw[1], raw[0])))\n",
    "    df = add_months_names(df)\n",
    "    df = df.explode(\"months\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df[\"create_datetime\"] = pd.to_datetime(df[\"create_datetime\"])\n",
    "    df.drop([\"period\", \"coordonnees\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "  \n",
    "res = data_extract(api_url)\n",
    "\n",
    "data = data_transformation(res)\n",
    "#\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Region: Provence-Alpes-Côte d'Azur, departement: Alpes-de-Haute-Provence country: France\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "# Create a geolocator object with a specific user_agent\n",
    "geolocator = Nominatim(user_agent=\"myApplication\")\n",
    "\n",
    "def get_location_info(latitude, longitude):\n",
    "    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "    address = location.raw['address']\n",
    "    region = address.get('state', '')\n",
    "    country = address.get('country', '')\n",
    "    departement = address.get('county', '')\n",
    "    return  region, country, departement\n",
    "\n",
    "# Example usage\n",
    "latitude =  44.3727858\n",
    "                           \n",
    "longitude =  6.8592967\n",
    "\n",
    "\n",
    "state, country,county = get_location_info(latitude, longitude)\n",
    "\n",
    "print(f\"Region: {state}, departement: {county} country: {country}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_months_names(df):\n",
    "    months_list = ['janvier', 'fevrier', 'mars', 'avril', 'mai', 'juin', 'juillet', 'août', 'septembre', 'octobre', 'novembre', 'decembre']\n",
    "    df_with_months = df.assign(\n",
    "        months=df['period'].apply(lambda x: [months_list[i] for i, value in enumerate(x) if value == 1])\n",
    "    )\n",
    "    return df_with_months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def ajust_create_datetime(df, target=\"create_datetime\", Groupby=\"index\"):\n",
    "    base_date = df[target].iloc[0]\n",
    "    df[\"diff\"] = ((df.groupby(Groupby).cumcount() * pd.DateOffset(months=1)))\n",
    "    df[\"transformed_date\"] = df[target] + df[\"diff\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>create_datetime</th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>structure</th>\n",
       "      <th>species_id</th>\n",
       "      <th>practices</th>\n",
       "      <th>update_datetime</th>\n",
       "      <th>region</th>\n",
       "      <th>departement</th>\n",
       "      <th>Pays</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>janvier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>janvier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>janvier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>janvier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>997</td>\n",
       "      <td>Un Parc national est un territoire reconnu com...</td>\n",
       "      <td>Coeur du Parc national du Mercantour</td>\n",
       "      <td>Parc National du Mercantour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-03-22</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>Alpes-de-Haute-Provence</td>\n",
       "      <td>France</td>\n",
       "      <td>janvier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>240</td>\n",
       "      <td>Nidification de l'Aigle royalLes pratiques qui...</td>\n",
       "      <td>Aigle royal</td>\n",
       "      <td>LPO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>Drôme</td>\n",
       "      <td>France</td>\n",
       "      <td>juillet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>240</td>\n",
       "      <td>Nidification de l'Aigle royalLes pratiques qui...</td>\n",
       "      <td>Aigle royal</td>\n",
       "      <td>LPO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>Drôme</td>\n",
       "      <td>France</td>\n",
       "      <td>juillet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>240</td>\n",
       "      <td>Nidification de l'Aigle royalLes pratiques qui...</td>\n",
       "      <td>Aigle royal</td>\n",
       "      <td>LPO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>Drôme</td>\n",
       "      <td>France</td>\n",
       "      <td>août</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>240</td>\n",
       "      <td>Nidification de l'Aigle royalLes pratiques qui...</td>\n",
       "      <td>Aigle royal</td>\n",
       "      <td>LPO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>Drôme</td>\n",
       "      <td>France</td>\n",
       "      <td>août</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>240</td>\n",
       "      <td>Nidification de l'Aigle royalLes pratiques qui...</td>\n",
       "      <td>Aigle royal</td>\n",
       "      <td>LPO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>Drôme</td>\n",
       "      <td>France</td>\n",
       "      <td>août</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1892 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     create_datetime   id                                        description  \\\n",
       "0         2021-03-26  997  Un Parc national est un territoire reconnu com...   \n",
       "1         2021-03-26  997  Un Parc national est un territoire reconnu com...   \n",
       "2         2021-03-26  997  Un Parc national est un territoire reconnu com...   \n",
       "3         2021-03-26  997  Un Parc national est un territoire reconnu com...   \n",
       "4         2021-03-26  997  Un Parc national est un territoire reconnu com...   \n",
       "...              ...  ...                                                ...   \n",
       "1887      2017-12-11  240  Nidification de l'Aigle royalLes pratiques qui...   \n",
       "1888      2017-12-11  240  Nidification de l'Aigle royalLes pratiques qui...   \n",
       "1889      2017-12-11  240  Nidification de l'Aigle royalLes pratiques qui...   \n",
       "1890      2017-12-11  240  Nidification de l'Aigle royalLes pratiques qui...   \n",
       "1891      2017-12-11  240  Nidification de l'Aigle royalLes pratiques qui...   \n",
       "\n",
       "                                      name                    structure  \\\n",
       "0     Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "1     Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "2     Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "3     Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "4     Coeur du Parc national du Mercantour  Parc National du Mercantour   \n",
       "...                                    ...                          ...   \n",
       "1887                           Aigle royal                          LPO   \n",
       "1888                           Aigle royal                          LPO   \n",
       "1889                           Aigle royal                          LPO   \n",
       "1890                           Aigle royal                          LPO   \n",
       "1891                           Aigle royal                          LPO   \n",
       "\n",
       "      species_id practices update_datetime                      region  \\\n",
       "0            NaN         3      2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "1            NaN         5      2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "2            NaN         6      2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "3            NaN         1      2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "4            NaN         2      2022-03-22  Provence-Alpes-Côte d'Azur   \n",
       "...          ...       ...             ...                         ...   \n",
       "1887         1.0         7      2018-03-13        Auvergne-Rhône-Alpes   \n",
       "1888         1.0         2      2018-03-13        Auvergne-Rhône-Alpes   \n",
       "1889         1.0         3      2018-03-13        Auvergne-Rhône-Alpes   \n",
       "1890         1.0         7      2018-03-13        Auvergne-Rhône-Alpes   \n",
       "1891         1.0         2      2018-03-13        Auvergne-Rhône-Alpes   \n",
       "\n",
       "                  departement    Pays   months  \n",
       "0     Alpes-de-Haute-Provence  France  janvier  \n",
       "1     Alpes-de-Haute-Provence  France  janvier  \n",
       "2     Alpes-de-Haute-Provence  France  janvier  \n",
       "3     Alpes-de-Haute-Provence  France  janvier  \n",
       "4     Alpes-de-Haute-Provence  France  janvier  \n",
       "...                       ...     ...      ...  \n",
       "1887                    Drôme  France  juillet  \n",
       "1888                    Drôme  France  juillet  \n",
       "1889                    Drôme  France     août  \n",
       "1890                    Drôme  France     août  \n",
       "1891                    Drôme  France     août  \n",
       "\n",
       "[1892 rows x 12 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# URL de l'API\n",
    "API_URL = \"https://biodiv-sports.fr/api/v2/sensitivearea/\"\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"myApplication\")\n",
    "\n",
    "def get_location_info(latitude, longitude):\n",
    "    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "    address = location.raw['address']\n",
    "    region = address.get('state', '')\n",
    "    country = address.get('country', '')\n",
    "    departement = address.get('county', '')\n",
    "    return region, departement, country\n",
    "\n",
    "def type_conversion(df):\n",
    "    str_cols = [\"id\", \"description\", \"name\", \"structure\", \"region\", \"departement\", \"Pays\"]\n",
    "    date_cols = [\"update_datetime\", \"create_datetime\"]\n",
    "\n",
    "    df[str_cols] = df[str_cols].apply(lambda col: col.astype(str))\n",
    "    df[date_cols] = df[date_cols].apply(lambda col: pd.to_datetime(col))\n",
    "\n",
    "    return df\n",
    "\n",
    "def convertir_date(date_string):\n",
    "    try:\n",
    "        date_obj = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    except ValueError:\n",
    "        return \"Format de date invalide. Assurez-vous que la chaîne est au format 'aaaa-mm-jjThh:mm:ss.ssssss+hh:mm'.\"\n",
    "\n",
    "def add_months_names(df):\n",
    "    months_list = ['janvier', 'fevrier', 'mars', 'avril', 'mai', 'juin', 'juillet', 'août', 'septembre', 'octobre', 'novembre', 'decembre']\n",
    "    df_with_months = df.assign(\n",
    "        months=df['period'].apply(lambda x: [months_list[i] for i, value in enumerate(x) if value == 1])\n",
    "    )\n",
    "    return df_with_months\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    cleaned_text = soup.get_text()\n",
    "    return cleaned_text \n",
    "\n",
    "def data_extract(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    res = response.json()\n",
    "    res = res[\"results\"]\n",
    "    return res\n",
    "\n",
    "def data_transformation(res):\n",
    "    data = [{\n",
    "        \"create_datetime\": convertir_date(item[\"create_datetime\"]),\n",
    "        \"id\": item[\"id\"],\n",
    "        \"description\": remove_html_tags(item[\"description\"][\"fr\"]),\n",
    "        \"name\": item[\"name\"][\"fr\"],\n",
    "        \"structure\": item[\"structure\"],\n",
    "        \"species_id\": item[\"species_id\"],\n",
    "        \"practices\": item[\"practices\"],\n",
    "        \"coordonnees\": item[\"geometry\"][\"coordinates\"][0][0][0] if item[\"geometry\"][\"type\"] == \"MultiPolygon\" else item[\"geometry\"][\"coordinates\"][0][0],\n",
    "        \"period\": [int(bool_) for bool_ in item[\"period\"]] if isinstance(item[\"period\"], list) else item[\"period\"],\n",
    "        \"update_datetime\": convertir_date(item[\"update_datetime\"])\n",
    "    } for item in res]\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df[[\"region\", \"departement\", \"Pays\"]] = list(df[\"coordonnees\"].apply(lambda raw: get_location_info(raw[1], raw[0])))\n",
    "    df = add_months_names(df)\n",
    "    df = df.explode(\"months\")\n",
    "    df = df.explode(\"practices\")\n",
    "    df.reset_index(inplace=True)\n",
    "    df = type_conversion(df)\n",
    "    df.drop([\"period\", \"coordonnees\",\"index\"], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "res = data_extract(API_URL)\n",
    "data = data_transformation(res)\n",
    "\n",
    "conn = sqlite3.connect(\"biodiv_sports.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_schema = '''CREATE TABLE IF NOT EXISTS sensitive_areas (\n",
    "                       id TEXT PRIMARY KEY,\n",
    "                       description TEXT,\n",
    "                       name TEXT,\n",
    "                       structure TEXT,\n",
    "                       species_id INTEGER,\n",
    "                       practices TEXT,\n",
    "                       create_datetime TIMESTAMP,\n",
    "                       update_datetime TIMESTAMP,\n",
    "                       région TEXT,\n",
    "                       département TEXT,\n",
    "                       pays TEXT,\n",
    "                       mois TEXT);'''\n",
    "\n",
    "cursor.execute(table_schema)\n",
    "conn.commit()\n",
    "\n",
    "processed_data = data.copy()\n",
    "processed_data.to_sql(name='sensitive_areas', con=conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"biodiv_sports.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_schema = '''CREATE TABLE IF NOT EXISTS sensitive_areas (\n",
    "                       id TEXT PRIMARY KEY,\n",
    "                       description TEXT,\n",
    "                       name TEXT,\n",
    "                       structure TEXT,\n",
    "                       species_id INTEGER,\n",
    "                       practices TEXT,\n",
    "                       create_datetime TIMESTAMP,\n",
    "                       update_datetime TIMESTAMP,\n",
    "                       région TEXT,\n",
    "                       département TEXT,\n",
    "                       pays TEXT,\n",
    "                       mois TEXT);'''\n",
    "\n",
    "cursor.execute(table_schema)\n",
    "conn.commit()\n",
    "\n",
    "processed_data = data.copy()\n",
    "processed_data.to_sql(name='sensitive_areas', con=conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1892 entries, 0 to 1891\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   create_datetime  1892 non-null   datetime64[ns]\n",
      " 1   id               1892 non-null   object        \n",
      " 2   description      1892 non-null   object        \n",
      " 3   name             1892 non-null   object        \n",
      " 4   structure        1892 non-null   object        \n",
      " 5   species_id       308 non-null    float64       \n",
      " 6   practices        1892 non-null   object        \n",
      " 7   update_datetime  1892 non-null   datetime64[ns]\n",
      " 8   region           1892 non-null   object        \n",
      " 9   departement      1892 non-null   object        \n",
      " 10  Pays             1892 non-null   object        \n",
      " 11  months           1892 non-null   object        \n",
      "dtypes: datetime64[ns](2), float64(1), object(9)\n",
      "memory usage: 177.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([''], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"provider\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/incompris04/mission_bdd/noteboo.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m     data \u001b[39m=\u001b[39m fetch_data()\n\u001b[0;32m---> <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m     transformed_dataframe \u001b[39m=\u001b[39m transform_data(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m     \u001b[39mprint\u001b[39m(transformed_dataframe\u001b[39m.\u001b[39mhead())\n",
      "\u001b[1;32m/home/incompris04/mission_bdd/noteboo.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(transformed_data)\u001b[39m.\u001b[39msort_values(\u001b[39m\"\u001b[39m\u001b[39mcreate_datetime\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m df[[\u001b[39m\"\u001b[39m\u001b[39mregion\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcounty\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m\"\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df[\u001b[39m\"\u001b[39m\u001b[39mcoordinate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m raw : extract_location_info(latitude\u001b[39m=\u001b[39mraw[\u001b[39m1\u001b[39m], longitude\u001b[39m=\u001b[39mraw[\u001b[39m0\u001b[39m])))\n\u001b[0;32m---> <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m df \u001b[39m=\u001b[39m add_month_names(df)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mexplode(\u001b[39m\"\u001b[39m\u001b[39mmois\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mcreate_datetime\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m\"\u001b[39m\u001b[39mcreate_datetime\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;32m/home/incompris04/mission_bdd/noteboo.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     mask \u001b[39m=\u001b[39m series \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m series[mask]\u001b[39m.\u001b[39many()\n\u001b[0;32m---> <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m filtered_df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39;49m\u001b[39mperiod\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(filter_valid_entries)]\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m df_with_months \u001b[39m=\u001b[39m filtered_df\u001b[39m.\u001b[39mcopy()\u001b[39m.\u001b[39massign(\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     moi\u001b[39m=\u001b[39m[months_list[i] \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(filtered_df[\u001b[39m'\u001b[39m\u001b[39mperiod\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39mif\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df_with_months\u001b[39m.\u001b[39mreindex(df\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/series.py:4908\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4780\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4781\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4787\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4788\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4789\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4790\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4906\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4907\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4908\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4909\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   4910\u001b[0m         func,\n\u001b[1;32m   4911\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[1;32m   4912\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[1;32m   4913\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   4914\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m   4915\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/home/incompris04/mission_bdd/noteboo.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Filter out series without at least one True value\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m mask \u001b[39m=\u001b[39m series \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://970-cs-393aeea2-3f5a-4102-9242-d427f491a8e5.cs-europe-west1-xedi.cloudshell.dev/home/incompris04/mission_bdd/noteboo.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mreturn\u001b[39;00m series[mask]\u001b[39m.\u001b[39;49many()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.geocoders import Nominatim\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up API url and user agent\n",
    "API_URL = \"https://biodiv-sports.fr/api/v2/sensitivearea/\"\n",
    "USER_AGENT = \"My Application\"\n",
    "\n",
    "# Initialize Nominatim with a custom user agent to comply with usage policy\n",
    "geolocator = Nominatim(user_agent=USER_AGENT)\n",
    "\n",
    "def extract_location_info(latitude, longitude):\n",
    "    \"\"\"Get detailed location information from latitude and longitude\"\"\"\n",
    "    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "    address = location.raw['address']\n",
    "    region = address.get('state', '')\n",
    "    county = address.get('county', '')\n",
    "    country = address.get('country', '')\n",
    "    return region, county, country\n",
    "\n",
    "def parse_and_format_date(date_string):\n",
    "    \"\"\"Convert string into a formatted date object or raise an exception on failure\"\"\"\n",
    "    try:\n",
    "        date_object = datetime.strptime(date_string, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "        return date_object.strftime(\"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        return \"Invalid date format. Ensure the input string matches '%Y-%m-%dT%H:%M:%S.%f%z'.\"\n",
    "\n",
    "def add_month_names(df):\n",
    "    \"\"\"Add month names based on period values within each row\"\"\"\n",
    "    months_list = ['janvier', 'février', 'mars', 'avril', 'mai', 'juin', 'juillet', 'août', 'septembre', 'octobre', 'novembre', 'décembre']\n",
    "\n",
    "    def filter_valid_entries(series):\n",
    "        \"\"\"Filter out series without at least one True value\"\"\"\n",
    "        mask = series != 0\n",
    "        return series[mask].any()\n",
    "\n",
    "    filtered_df = df[df['period'].apply(filter_valid_entries)]\n",
    "\n",
    "    df_with_months = filtered_df.copy().assign(\n",
    "        moi=[months_list[i] for i, value in enumerate(filtered_df['period']) if value == 1]\n",
    "    )\n",
    "\n",
    "    return df_with_months.reindex(df.index)\n",
    "\n",
    "def clean_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from text content\"\"\"\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"Fetch sensitive area data using the provided API endpoint.\"\"\"\n",
    "    response = requests.get(API_URL)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    return result[\"results\"]\n",
    "\n",
    "def transform_data(data):\n",
    "    \"\"\"Transform fetched data into a usable Pandas DataFrame\"\"\"\n",
    "    transformed_data = []\n",
    "    for entry in data:\n",
    "        coordinates = entry[\"geometry\"][\"coordinates\"][0][0][0] if entry[\"geometry\"][\"type\"] == \"MultiPolygon\" else entry[\"geometry\"][\"coordinates\"][0][0]\n",
    "        new_entry = {\n",
    "            \"create_datetime\": parse_and_format_date(entry[\"create_datetime\"]),\n",
    "            \"id\": entry[\"id\"],\n",
    "            \"description\": clean_html_tags(entry[\"description\"][\"fr\"]),\n",
    "            \"name\": entry[\"name\"][\"fr\"],\n",
    "            \"structure\": entry[\"structure\"],\n",
    "            \"elevation\": entry[\"elevation\"],\n",
    "            \"provider\": entry[\"provider\"],\n",
    "            \"coordinate\": coordinates,\n",
    "            \"period\": [int(value) for value in entry[\"period\"]] if isinstance(entry[\"period\"], list) else entry[\"period\"],\n",
    "            \"update_datetime\": parse_and_format_date(entry[\"update_datetime\"])\n",
    "        }\n",
    "        transformed_data.append(new_entry)\n",
    "\n",
    "    df = pd.DataFrame(transformed_data).sort_values(\"create_datetime\")\n",
    "    df[[\"region\", \"county\", \"country\"]] = list(df[\"coordinate\"].apply(lambda raw : extract_location_info(latitude=raw[1], longitude=raw[0])))\n",
    "    df = add_month_names(df)\n",
    "    df = df.explode(\"mois\").reset_index(drop=True)\n",
    "    df[\"create_datetime\"] = pd.to_datetime(df[\"create_datetime\"])\n",
    "    df = df.drop(columns=[\"period\", \"coordinate\"])\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = fetch_data()\n",
    "    transformed_dataframe = transform_data(data)\n",
    "    print(transformed_dataframe.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
